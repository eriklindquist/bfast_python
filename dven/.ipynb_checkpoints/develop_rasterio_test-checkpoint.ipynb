{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU implementation of Bfastmonitor using Python\n",
    "The bfast package provides a highly-efficient parallel implementation for the Breaks For Additive Season and Trend (BFASTmonitor) proposed by Verbesselt et al. (2012). This notebook is based on the novel implementation, which takes advanatage of GPUs (Gieseke et al. (2020))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This code runs bfastmonitor over an entire time series folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script below runs bfastmonitor over the timeseries data downloaded in SEPAL in blocks, and patches together tiles to export mean magnitudes and breaks as geotiffs, pngs, and .npy files. The output is also displayed in a digital map. Make sure to run through the cells sequentially.\n",
    "\n",
    "* Make sure to select the G4 (recommended) or G8 when accessing the terminal. \n",
    "\n",
    "* First download data using the SEPAL time series downloader (not in this script). The downloads will be saved in your downloads folder and look like: /home/'username'/downloads/Time_series_2020-09-01_16-22-26/0|1|2|3\n",
    "\n",
    "* Import packages\n",
    "\n",
    "* Select data\n",
    "\n",
    "* Set parameters\n",
    "\n",
    "* Select monitoring period\n",
    "\n",
    "* Run bfastmonitor and save intermediate output\n",
    "\n",
    "* Load output\n",
    "\n",
    "* Merge and save output\n",
    "\n",
    "* Display output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The timeseries class is a wrapper for using SEPAL timeseries data with bfast. \n",
      "    It wraps together a data tile with an associated dates file and metadata. \n",
      "    It also allows for saving and loading the output rasters in a specified directory. \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import expanduser\n",
    "\n",
    "import wget\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import copy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "\n",
    "import rasterio\n",
    "#import datetime\n",
    "import bisect\n",
    "\n",
    "import json\n",
    "\n",
    "import bfast\n",
    "#from bfast import BFASTMonitor\n",
    "#from bfast.utils import crop_data_dates\n",
    "\n",
    "import csv\n",
    "from shutil import copyfile\n",
    "import pandas as pd\n",
    "from osgeo import gdal, gdal_array, osr\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout\n",
    "from ipyfilechooser import FileChooser\n",
    "import folium\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "\n",
    "# import functions from functions.py\n",
    "from functions import set_base_output_dir, set_output_dir, get_data_dict, merge_tiles, set_paths, _find_index_date, normalize, select_negatives, get_julian_dates\n",
    "from plotting_funcs import save_plot, merge_plots, classify_output, plot_output_matplotlib, export_GTiff, classify_magnitudes, merge_plots2\n",
    "\n",
    "# Import the Timeseries class from time_series.py\n",
    "from time_series import Timeseries\n",
    "print(Timeseries.__doc__)\n",
    "\n",
    "# Import widgets for GUI parameter selection\n",
    "from widgets import get_widgets, get_dates_widgets\n",
    "output_directory_chooser, k_chooser,freq_chooser,trend_chooser,hfrac_chooser,level_chooser,backend_chooser, load_chooser, block_size_chooser, plot_display_data_chooser = get_widgets()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select output directory name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22483d0f4d274c87b287bb0a008962e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='', description='Output storage name: (country/location name, e.g. \"Guyana\")'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(output_directory_chooser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory name: stored_time_series/rasterio_test\n"
     ]
    }
   ],
   "source": [
    "base_output_dir = set_base_output_dir(output_directory_chooser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select your timeseries folder. They are regularly stored in downloads/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac5a1ba0fc3f411ca0e2324b4cc94f9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/home/lindquist', filename='', title='HTML(value='', layout=Layout(display='none'))', show_h…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = expanduser(\"~\")\n",
    "file_chooser = FileChooser(path)\n",
    "display(file_chooser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lindquist/downloads/Time_series_2021-03-26_15-08-46/\n"
     ]
    }
   ],
   "source": [
    "timeseries_directory = file_chooser.selected\n",
    "\n",
    "if not timeseries_directory:\n",
    "    raise Exception(\"Please choose a time series directory above with the file selector\")\n",
    "else:\n",
    "    print(timeseries_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the directories you are interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad7020e03005422b884177ae038d42f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Checkbox(value=True, description='0'),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "items = [widgets.Checkbox(value = True,description = i) for i in os.listdir(timeseries_directory)]\n",
    "widgets.VBox(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9819bc9e53b1469dacb9f50b88d560a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='k, harmonic terms', layout=Layout(height='auto', width='500px'), o…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3bcaf42d878443dad371af94c6d196c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=365, description='freq, frequency of seasonal model (days)', layout=Layo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e211ee8f54c04fae9edc2da8ba99e908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Checkbox(value=False, description='add trend', layout=Layout(height='auto', width='500px…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04ac198bd32549929d2e16fc05b57df2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.25, description='Bandwith relative to sample size', layout=Layout(he…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "643abc77b693439097e094ace7c27057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectionSlider(description='Significance level of the monitoring', layout=Layout(height…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0f06364ca4844c28a6ce676a658e2a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='backend', layout=Layout(height='auto', width='500px'), options=('o…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Choose parameters\n",
    "display(k_chooser)\n",
    "display(freq_chooser)\n",
    "display(trend_chooser)\n",
    "display(hfrac_chooser)\n",
    "display(level_chooser)\n",
    "display(backend_chooser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "k = k_chooser.result\n",
    "freq = freq_chooser.result\n",
    "trend = trend_chooser.result\n",
    "hfrac = hfrac_chooser.result\n",
    "level = round(1 - level_chooser.result,3)\n",
    "backend = backend_chooser.result\n",
    "verbose = 1\n",
    "device_id = 0\n",
    "\n",
    "parameter_string =  'k%sf%st%sh%sl%s' % (k,freq,trend,hfrac,level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose history and monitoring period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1353df154d644480a270302cbac63cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectionRangeSlider(description='Select the monitoring date range: ', index=(0, 268), l…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe0e2d3abf9943629fcfe821d9513996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectionSlider(description='Start history period:', options=(('2016-01-10', Timestamp('…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dates_path = os.path.join(timeseries_directory, \"0/dates.csv\")\n",
    "\n",
    "# Store dates_file\n",
    "with open(dates_path) as f:\n",
    "    dates_list = f.read().split('\\n')\n",
    "    dates = [datetime.strptime(d, '%Y-%m-%d') for d in dates_list if len(d) > 0]\n",
    "\n",
    "start_date = dates[0]\n",
    "end_date = dates[-1]\n",
    "pandas_dates = pd.date_range(start_date, end_date, freq='W')\n",
    "\n",
    "options =  [(date.strftime('%Y-%m-%d'), date) for date in pandas_dates]\n",
    "index = (0, len(options)-1)\n",
    "\n",
    "monitoring_period_chooser, history_period_chooser = get_dates_widgets(options = options, index = index)\n",
    "\n",
    "display(monitoring_period_chooser)\n",
    "display(history_period_chooser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start monitoring:  2019-01-06 00:00:00\n",
      "end monitoring:  2021-02-28 00:00:00\n",
      "start history:  2016-01-10 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Store monitoring parameters\n",
    "start_monitor, end_monitor = monitoring_period_chooser.result\n",
    "start_hist = history_period_chooser.result\n",
    "\n",
    "print(\"start monitoring: \" , start_monitor)\n",
    "print(\"end monitoring: \" , end_monitor)\n",
    "print(\"start history: \" ,  start_hist)\n",
    "\n",
    "if history_period_chooser.result > start_monitor:\n",
    "    raise Exception(\"Your history period must start before the monitoring period\")\n",
    "\n",
    "if start_monitor < dates[50]:\n",
    "    raise Warning(\"Your history period is relatively short, did you move the monitoring date range to a later date?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breaksToDecimalYear(index,monitoringDates):\n",
    "    if index < 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        breakDate = monitoringDates[index-1]\n",
    "        return breakDate.year + (breakDate.timetuple().tm_yday - 1)/365\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'driver': 'VRT', 'dtype': 'float64', 'nodata': 0.0, 'width': 638, 'height': 152, 'count': 234, 'crs': CRS.from_epsg(4326), 'transform': Affine(0.00026949458523585533, 0.0, -77.66402755161006,\n",
      "       0.0, -0.00026949458523585533, -2.8234947695160684), 'blockxsize': 128, 'blockysize': 128, 'tiled': True}\n",
      "{'driver': 'GTiff', 'dtype': 'float32', 'nodata': 0.0, 'width': 638, 'height': 152, 'count': 2, 'crs': CRS.from_epsg(4326), 'transform': Affine(0.00026949458523585533, 0.0, -77.66402755161006,\n",
      "       0.0, -0.00026949458523585533, -2.8234947695160684), 'blockxsize': 128, 'blockysize': 128, 'tiled': True}\n",
      "[[[         nan          nan          nan ...          nan          nan\n",
      "            nan]\n",
      "  [         nan          nan          nan ...          nan          nan\n",
      "            nan]\n",
      "  [         nan          nan          nan ...          nan          nan\n",
      "            nan]\n",
      "  ...\n",
      "  [         nan          nan          nan ...          nan          nan\n",
      "            nan]\n",
      "  [         nan          nan          nan ...          nan 2020.7233\n",
      "   2020.7233   ]\n",
      "  [         nan          nan          nan ... 2020.7014    2020.7233\n",
      "            nan]]\n",
      "\n",
      " [[   0.           0.           0.        ...    0.           0.\n",
      "      0.       ]\n",
      "  [ 149.29613     77.57487     -7.5766873 ...  101.47214    549.6969\n",
      "    201.67734  ]\n",
      "  [  59.49463    177.38068    135.00673   ...  506.74277    446.2915\n",
      "    207.51523  ]\n",
      "  ...\n",
      "  [   0.           0.           0.        ...  358.07922    -87.234505\n",
      "   -105.32986  ]\n",
      "  [   0.           0.           0.        ...  538.7269     103.9605\n",
      "   -234.74097  ]\n",
      "  [   0.           0.           0.        ... -154.7929    -229.34157\n",
      "     20.825474 ]]]\n",
      "[[[         nan          nan          nan ...          nan          nan\n",
      "            nan]\n",
      "  [         nan          nan          nan ...          nan          nan\n",
      "            nan]\n",
      "  [         nan 2019.9562    2019.9342    ...          nan          nan\n",
      "            nan]\n",
      "  ...\n",
      "  [         nan          nan 2020.6136    ...          nan          nan\n",
      "            nan]\n",
      "  [         nan          nan          nan ...          nan          nan\n",
      "            nan]\n",
      "  [         nan          nan          nan ...          nan          nan\n",
      "            nan]]\n",
      "\n",
      " [[   0.           0.           0.        ...    0.           0.\n",
      "      0.       ]\n",
      "  [-422.911     -291.95148   -505.8646    ...   57.93049    -41.303425\n",
      "    -17.537254 ]\n",
      "  [-294.26965   -766.45416   -682.49066   ...   -7.7805386   72.82517\n",
      "     96.78699  ]\n",
      "  ...\n",
      "  [ 263.99615     80.562454   -81.77742   ...  -46.093964   -78.49504\n",
      "   -120.78243  ]\n",
      "  [   9.135774   326.73026     87.73635   ...    9.8241625  -34.86398\n",
      "     86.771034 ]\n",
      "  [ 105.95842     99.560974  -105.893654  ...  -74.32694     -9.977084\n",
      "   -168.65845  ]]]\n",
      "[[[         nan          nan          nan ...          nan          nan\n",
      "            nan]\n",
      "  [         nan          nan          nan ...          nan          nan\n",
      "            nan]\n",
      "  [         nan          nan          nan ...          nan          nan\n",
      "            nan]\n",
      "  ...\n",
      "  [         nan          nan          nan ...          nan          nan\n",
      "            nan]\n",
      "  [         nan          nan          nan ...          nan          nan\n",
      "            nan]\n",
      "  [         nan          nan          nan ...          nan          nan\n",
      "            nan]]\n",
      "\n",
      " [[   0.           0.           0.        ...    0.           0.\n",
      "      0.       ]\n",
      "  [ 101.925804    65.2386     -10.579765  ... -113.61102   -167.93906\n",
      "   -173.02502  ]\n",
      "  [  53.515835   167.57965    143.36255   ...  -47.135612  -121.767784\n",
      "    -69.98706  ]\n",
      "  ...\n",
      "  [  14.843802    64.70579   -144.86012   ...   40.35255     90.085594\n",
      "     82.66785  ]\n",
      "  [  45.6368    -176.35942   -134.75195   ...   49.34488    -47.441383\n",
      "    -35.742867 ]\n",
      "  [-191.20186     52.408173   -20.088371  ...    3.2036452  -74.00258\n",
      "    -67.42451  ]]]\n",
      "[[[         nan          nan          nan ...          nan          nan\n",
      "            nan]\n",
      "  [         nan          nan          nan ...          nan          nan\n",
      "            nan]\n",
      "  [         nan          nan          nan ...          nan          nan\n",
      "            nan]\n",
      "  ...\n",
      "  [         nan          nan          nan ...          nan          nan\n",
      "            nan]\n",
      "  [         nan          nan          nan ...          nan          nan\n",
      "            nan]\n",
      "  [         nan          nan          nan ...          nan          nan\n",
      "            nan]]\n",
      "\n",
      " [[   0.           0.           0.        ...    0.           0.\n",
      "      0.       ]\n",
      "  [  13.535946    13.404549  -130.55772   ...    0.           0.\n",
      "      0.       ]\n",
      "  [ -32.235477   -70.56791    -13.036415  ...   -1.1476223  -20.751335\n",
      "     62.384212 ]\n",
      "  ...\n",
      "  [ -87.19074   -133.8926    -158.14085   ...  -57.776       63.667847\n",
      "     18.910288 ]\n",
      "  [ -19.523811   -52.623463  -181.79451   ... -141.44861   -140.08528\n",
      "    -47.802155 ]\n",
      "  [  63.78347    -55.84198    -91.326324  ...    5.750622   -80.9803\n",
      "    214.34285  ]]]\n",
      "[[[         nan          nan          nan ...          nan          nan\n",
      "            nan]\n",
      "  [         nan          nan          nan ...          nan          nan\n",
      "            nan]\n",
      "  [         nan          nan          nan ...          nan          nan\n",
      "            nan]\n",
      "  ...\n",
      "  [         nan          nan          nan ...          nan          nan\n",
      "            nan]\n",
      "  [         nan          nan          nan ...          nan          nan\n",
      "            nan]\n",
      "  [         nan          nan          nan ...          nan          nan\n",
      "            nan]]\n",
      "\n",
      " [[   0.           0.           0.        ...    0.           0.\n",
      "      0.       ]\n",
      "  [   0.           0.           0.        ...    0.           0.\n",
      "      0.       ]\n",
      "  [  28.826294    77.43505    -62.060314  ... -180.0184    -192.54825\n",
      "     70.48575  ]\n",
      "  ...\n",
      "  [ -49.077713   -59.974247    13.6478815 ...   25.978828    15.059393\n",
      "      0.       ]\n",
      "  [-120.60566   -149.5088    -109.04251   ... -159.51437    -69.97022\n",
      "      0.       ]\n",
      "  [  42.98412     20.620317   160.78131   ...  -75.9116     -57.32723\n",
      "      0.       ]]]\n",
      "[[[        nan         nan         nan ...         nan         nan\n",
      "           nan]\n",
      "  [        nan         nan         nan ...         nan         nan\n",
      "           nan]\n",
      "  [        nan         nan         nan ...         nan         nan\n",
      "           nan]\n",
      "  ...\n",
      "  [        nan         nan         nan ...         nan         nan\n",
      "           nan]\n",
      "  [        nan         nan         nan ...         nan         nan\n",
      "           nan]\n",
      "  [        nan         nan         nan ...         nan         nan\n",
      "           nan]]\n",
      "\n",
      " [[   0.          0.          0.       ... -290.78494   -79.591805\n",
      "     33.026176]\n",
      "  [   0.          0.          0.       ... -235.30386   -11.879738\n",
      "    -53.934578]\n",
      "  [   0.          0.          0.       ...  129.78023    62.56749\n",
      "   -102.3808  ]\n",
      "  ...\n",
      "  [   0.          0.          0.       ...   15.901258   75.96602\n",
      "     78.13692 ]\n",
      "  [   0.          0.          0.       ...  252.62085   185.65363\n",
      "   -166.35355 ]\n",
      "  [   0.          0.          0.       ...    0.          0.\n",
      "      0.      ]]]\n",
      "[[[         nan          nan          nan ...          nan          nan\n",
      "            nan]\n",
      "  [         nan          nan          nan ...          nan          nan\n",
      "            nan]\n",
      "  [         nan          nan          nan ...          nan          nan\n",
      "            nan]\n",
      "  ...\n",
      "  [         nan          nan          nan ...          nan          nan\n",
      "            nan]\n",
      "  [         nan          nan          nan ...          nan          nan\n",
      "            nan]\n",
      "  [         nan          nan          nan ...          nan          nan\n",
      "            nan]]\n",
      "\n",
      " [[ 184.56166     30.445616  -192.35364   ...  -43.664818   -37.37922\n",
      "    -81.04707  ]\n",
      "  [ -37.52648    170.56027    263.48462   ...   45.02495      7.933759\n",
      "      8.809478 ]\n",
      "  [ 100.81443    -16.02298    291.01868   ...   29.76348    -54.385925\n",
      "    144.40836  ]\n",
      "  ...\n",
      "  [  -1.4691656  219.80196    233.68234   ...  115.51999    -45.20758\n",
      "    -29.53151  ]\n",
      "  [  63.424957   622.4791     666.4215    ...    0.           0.\n",
      "      0.       ]\n",
      "  [   0.           0.           0.        ...    0.           0.\n",
      "      0.       ]]]\n",
      "[[[         nan          nan          nan ...          nan          nan\n",
      "            nan]\n",
      "  [         nan          nan          nan ...          nan          nan\n",
      "            nan]\n",
      "  [         nan          nan          nan ...          nan          nan\n",
      "            nan]\n",
      "  ...\n",
      "  [         nan          nan          nan ...          nan          nan\n",
      "            nan]\n",
      "  [         nan          nan          nan ...          nan          nan\n",
      "            nan]\n",
      "  [         nan          nan          nan ...          nan          nan\n",
      "            nan]]\n",
      "\n",
      " [[-242.54822    -81.25183    -28.31336   ...   94.92656     -8.745938\n",
      "   -102.96139  ]\n",
      "  [ -75.219185   -11.48438     16.838102  ...   11.674658    21.859875\n",
      "    -95.39217  ]\n",
      "  [   3.0278487  -56.390537    78.12191   ...  -80.5448     -31.195038\n",
      "   -146.89471  ]\n",
      "  ...\n",
      "  [ -12.211734    14.026275    90.73607   ...    0.           0.\n",
      "      0.       ]\n",
      "  [   0.           0.           0.        ...    0.           0.\n",
      "      0.       ]\n",
      "  [   0.           0.           0.        ...    0.           0.\n",
      "      0.       ]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[        nan         nan         nan ...         nan         nan\n",
      "           nan]\n",
      "  [        nan         nan         nan ...         nan         nan\n",
      "           nan]\n",
      "  [        nan         nan         nan ...         nan         nan\n",
      "           nan]\n",
      "  ...\n",
      "  [        nan         nan         nan ...         nan         nan\n",
      "           nan]\n",
      "  [        nan         nan         nan ...         nan         nan\n",
      "           nan]\n",
      "  [        nan         nan         nan ...         nan         nan\n",
      "           nan]]\n",
      "\n",
      " [[   1.648795 -118.14916   -99.30838  ...  -15.600133  -30.049652\n",
      "    132.3269  ]\n",
      "  [-116.81673  -153.9476   -200.31255  ... -154.32205   -40.871567\n",
      "   -143.3111  ]\n",
      "  [-121.858665  -44.340008  -20.641624 ... -167.31277  -147.36569\n",
      "    -74.36404 ]\n",
      "  ...\n",
      "  [   0.          0.          0.       ...    0.          0.\n",
      "      0.      ]\n",
      "  [   0.          0.          0.       ...    0.          0.\n",
      "      0.      ]\n",
      "  [   0.          0.          0.       ...    0.          0.\n",
      "      0.      ]]]\n",
      "[[[        nan         nan         nan ...         nan         nan\n",
      "           nan]\n",
      "  [        nan         nan         nan ...         nan         nan\n",
      "           nan]\n",
      "  [        nan         nan         nan ...         nan         nan\n",
      "           nan]\n",
      "  ...\n",
      "  [        nan         nan         nan ...         nan         nan\n",
      "           nan]\n",
      "  [        nan         nan         nan ...         nan         nan\n",
      "           nan]\n",
      "  [        nan         nan         nan ...         nan         nan\n",
      "           nan]]\n",
      "\n",
      " [[ -14.219449 -141.34041  -169.03766  ... -110.29583    52.776867\n",
      "      0.      ]\n",
      "  [ -62.67186  -281.25958  -392.62292  ...  -98.02037    25.299349\n",
      "      0.      ]\n",
      "  [ 164.82509  -253.27295  -118.00476  ...  -52.604996  108.630325\n",
      "      0.      ]\n",
      "  ...\n",
      "  [   0.          0.          0.       ...    0.          0.\n",
      "      0.      ]\n",
      "  [   0.          0.          0.       ...    0.          0.\n",
      "      0.      ]\n",
      "  [   0.          0.          0.       ...    0.          0.\n",
      "      0.      ]]]\n"
     ]
    }
   ],
   "source": [
    "# set path to dates file and create Timeseries objects of tiles\n",
    "load_list=[]\n",
    "for xi in items:\n",
    "    if xi.value == True:\n",
    "        load_list.append(xi.description)\n",
    "\n",
    "#run_dict = {}\n",
    "for directory in load_list:\n",
    "    \n",
    "    segment_location = timeseries_directory + directory + \"/\"\n",
    "    save_location = base_output_dir +\"/\"+ directory + \"/\"\n",
    "    \n",
    "    src_1 = rasterio.open(segment_location + 'stack.vrt', GEOREF_SOURCES='INTERNAL')\n",
    "    geoprofile = src_1.profile.copy()\n",
    "    print(geoprofile)\n",
    "    geoprofile['driver'] = 'GTiff'\n",
    "    geoprofile['count'] = 2\n",
    "    geoprofile['dtype'] = 'float32'\n",
    "    print(geoprofile)\n",
    "    dst = rasterio.open(save_location + 'bfast_outputs.tif', 'w', **geoprofile)\n",
    "\n",
    "    for block_index, window in src_1.block_windows(1):\n",
    "    #print((ji, window))\n",
    "        indexedRasterTimeSeries = src_1.read(window=window)\n",
    "    #geoprofile = raster.profile\n",
    "##indexedRasterGeoTiff = rasterio.open('../Input_data/Time_series_2020-10-22_20-07-44/0/Congo_block1.tif')\n",
    "##indexedRasterTimeSeries = indexedRasterGeoTiff.read()\n",
    "##indexedRasterGeoTiff.close()\n",
    "        indexedRasterTimeSeries = indexedRasterTimeSeries.astype(np.int16)\n",
    "        indexedRasterTimeSeries[np.isnan(indexedRasterTimeSeries)] = 0\n",
    "        observationDates = pd.read_csv(segment_location + 'dates.csv',header=None)[0]\n",
    "        observationDates = [datetime.strptime(date, \"%Y-%m-%d\") for date in observationDates]\n",
    "        mon = bfast.BFASTMonitor(start_monitor = start_monitor, \n",
    "                              freq = freq,\n",
    "                              k = k,\n",
    "                              hfrac = hfrac,\n",
    "                              trend = trend,\n",
    "                              level = level,\n",
    "                              backend=backend)\n",
    "                              #verbose=verbose)\n",
    "                              #device_id=device_id) #or opencl for GPU version\n",
    "        monitoringDates = observationDates[bisect.bisect(observationDates, mon.start_monitor):]\n",
    "        mon.fit(indexedRasterTimeSeries, observationDates)\n",
    "    \n",
    "        breaksToDecimalYear = np.vectorize(breaksToDecimalYear,excluded=[1])\n",
    "        decimal_breaks = breaksToDecimalYear(mon.breaks,monitoringDates)\n",
    "        monitoringResults = np.stack((decimal_breaks,mon.magnitudes)).astype(np.float32)\n",
    "        print(monitoringResults)\n",
    "#    with rasterio.Env():\n",
    "#        geoprofile.update(\n",
    "#            dtype=rasterio.float32,\n",
    "#            driver='GTiff',\n",
    "#            count=2)\n",
    "#        print(geoprofile)\n",
    "        dst.write(monitoringResults.astype(rasterio.float32), window=window)\n",
    "    \n",
    "dst.close()\n",
    "src_1.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(segment_location)\n",
    "#print(save_location)\n",
    "print(data_list)\n",
    "print(run_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose block size (512 recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(block_size_chooser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run bfast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_block = y_block = block_size_chooser.result\n",
    "\n",
    "\n",
    "for data_list in run_dict:\n",
    "    \n",
    "#    # loading bar\n",
    "#    with tqdm(total=len(run_dict)) as pbar1:\n",
    "        \n",
    "        # Set save location\n",
    "    save_location = base_output_dir + \"/\" + data_list\n",
    "    print(save_location)\n",
    "    if not os.path.exists(save_location):\n",
    "        os.makedirs(save_location)\n",
    "        \n",
    "        # loop over tile(s) in the data_list\n",
    "#        for counter, tile in enumerate(run_dict[data_list]):\n",
    "#            pbar1.set_description(\"Processing tile %s out of %s\" % (counter+1, len(run_dict[data_list])) )\n",
    "    \n",
    "    \n",
    "    src_1 = rasterio.open(data_list + '/stack.vrt', GEOREF_SOURCES='INTERNAL')\n",
    "    geoprofile = src_1.profile.copy()\n",
    "    print(geoprofile)\n",
    "    geoprofile['driver'] = 'GTiff'\n",
    "    geoprofile['count'] = 2\n",
    "    geoprofile['dtype'] = 'float32'\n",
    "    print(geoprofile)\n",
    "    dst = rasterio.open(save_location + '/bfast_results_python_v4.tif', 'w', **geoprofile)\n",
    "\n",
    "    for block_index, window in src_1.block_windows(1):\n",
    "    #print((ji, window))\n",
    "        indexedRasterTimeSeries = src_1.read(window=window)\n",
    "    #geoprofile = raster.profile\n",
    "##indexedRasterGeoTiff = rasterio.open('../Input_data/Time_series_2020-10-22_20-07-44/0/Congo_block1.tif')\n",
    "##indexedRasterTimeSeries = indexedRasterGeoTiff.read()\n",
    "##indexedRasterGeoTiff.close()\n",
    "        indexedRasterTimeSeries = indexedRasterTimeSeries.astype(np.int16)\n",
    "        indexedRasterTimeSeries[np.isnan(indexedRasterTimeSeries)] = 0\n",
    "        observationDates = pd.read_csv('downloads/Time_series_2021-03-26_15-08-46/0/dates.csv',header=None)[0]\n",
    "        observationDates = [datetime.datetime.strptime(date, \"%Y-%m-%d\") for date in observationDates]\n",
    "        mon = bfast.BFASTMonitor(start_monitor = start_monitor, \n",
    "                              end_monitor = end_monitor,\n",
    "                              start_hist = start_hist,\n",
    "                              freq = freq,\n",
    "                              k = k,\n",
    "                              hfrac = hfrac,\n",
    "                              trend = trend,\n",
    "                              level = level,\n",
    "                              backend=backend,\n",
    "                              verbose=verbose,\n",
    "                              device_id=device_id)\n",
    "        \n",
    "        monitoringDates = observationDates[bisect.bisect(observationDates, mon.start_monitor):]\n",
    "        mon.fit(indexedRasterTimeSeries, observationDates)\n",
    "    \n",
    "        breaksToDecimalYear = np.vectorize(breaksToDecimalYear,excluded=[1])\n",
    "        decimal_breaks = breaksToDecimalYear(mon.breaks,monitoringDates)\n",
    "        monitoringResults = np.stack((decimal_breaks,mon.magnitudes)).astype(np.float32)\n",
    "        print(monitoringResults)\n",
    "#    with rasterio.Env():\n",
    "#        geoprofile.update(\n",
    "#            dtype=rasterio.float32,\n",
    "#            driver='GTiff',\n",
    "#            count=2)\n",
    "#        print(geoprofile)\n",
    "        dst.write(monitoringResults.astype(rasterio.float32), window=window)\n",
    "    \n",
    "dst.close()\n",
    "src_1.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Set parameters\n",
    "    tile.set_bfast_parameters(start_monitor = start_monitor, \n",
    "                              end_monitor = end_monitor,\n",
    "                              start_hist = start_hist,\n",
    "                              freq = freq,\n",
    "                              k = k,\n",
    "                              hfrac = hfrac,\n",
    "                              trend = trend,\n",
    "                              level = level,\n",
    "                              backend=backend,\n",
    "                              verbose=verbose,\n",
    "                              device_id=device_id)\n",
    "            \n",
    "    # Print parameters to screen\n",
    "    tile.get_bfast_parameters()\n",
    "            \n",
    "    # Loop over blocks using RASTERIO\n",
    "    tile.loop_blocks_erik\n",
    "\n",
    "            # Loop over blocks of set size\n",
    "#            tile.loop_blocks(x_block_size = x_block,\n",
    "#                                y_block_size = y_block)\n",
    "            \n",
    "    # Store logfile of output\n",
    "    tile.log_all_output(output_dir_name=save_location, parameter_string = parameter_string)\n",
    "            \n",
    "    # Delete data from local memory\n",
    "    run_dict[data_list][counter] = '0'\n",
    "    del(tile)\n",
    "\n",
    "#            pbar1.update(1)\n",
    "\n",
    "#    pbar1.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load saved output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dict = {}\n",
    "for directory in load_list:\n",
    "    \n",
    "    segment_location = timeseries_directory + directory + \"/\"\n",
    "    dates_location =  timeseries_directory + directory + \"/dates.csv\"\n",
    "    \n",
    "    data_list = set_paths(timeseries_directory = segment_location,\n",
    "                            sh = start_hist,\n",
    "                            sm = start_monitor,\n",
    "                            em = end_monitor,\n",
    "                            parameter_string = parameter_string)\n",
    "    run_dict[directory] = data_list\n",
    "    \n",
    "    for tile in data_list:\n",
    "        tile.start_monitor, tile.end_monitor = monitoring_period_chooser.result\n",
    "        tile.start_hist = history_period_chooser.result \n",
    "        tile.crop_dates(tile.dates)\n",
    "        tile.load_breaks_means_arrays_from_file(output_dir_name = base_output_dir + \"/\" +  directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output statistics and geotifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ts_dir in run_dict:\n",
    "    \n",
    "    print(\"dir\" , ts_dir)\n",
    "    save_location = base_output_dir + \"/\" + ts_dir\n",
    "    tiles_data = run_dict[ts_dir]\n",
    "    \n",
    "    # Print statistics\n",
    "    perc_lacking_data_sum, perc_breaks_sum= 0,0\n",
    "    for tile in tiles_data:\n",
    "        print(tile)\n",
    "        minus2count,minus1count,perc_lacking_data,perc_breaks = tile.check_arrays()\n",
    "        perc_breaks_sum += perc_breaks\n",
    "        perc_lacking_data_sum+= perc_lacking_data\n",
    "        \n",
    "    print(\"percentage breaks found\", perc_breaks_sum/len(tiles_data))\n",
    "    print(\"percentage cells lacking data to find results found\", perc_lacking_data_sum/len(tiles_data) , \"\\n\")\n",
    "    \n",
    "    # Merge tiles\n",
    "    if len(tiles_data) > 1:\n",
    "        means_orig, breaks_orig = merge_tiles(tiles_data,output_dir_name = save_location)\n",
    "    else:\n",
    "        means_orig = tiles_data[0].means_array\n",
    "        breaks_orig = tiles_data[0].breaks_array\n",
    "\n",
    "    # Export magnitudes and breaks\n",
    "    save_plot(means_orig, save_location, save_name = \"magnitudes_\" + ts_dir)\n",
    "    export_GTiff(tiles_data, output_dir = save_location, array = means_orig, output_name = \"magnitudes_\" + ts_dir)\n",
    "    export_GTiff(tiles_data, output_dir = save_location, array = breaks_orig, output_name = \"breaks_indexed_\" + ts_dir)\n",
    "\n",
    "    # Classify means \n",
    "    classified_means = classify_magnitudes(means_orig)\n",
    "    classified_means = np.nan_to_num(classified_means,nan=0).astype(\"uint16\")\n",
    "    export_GTiff(tiles_data, output_dir = save_location, array = classified_means, output_name = \"magnitudes_classified_\" + ts_dir)\n",
    "    \n",
    "    # add colors to classified raster\n",
    "    func = \"oft-addpct.py\"\n",
    "    output_key = save_location.replace(\"/\",\"-\").split(\"-\")[1]\n",
    "    clas_tif = save_location + \"/geotifs/magnitudes_classified_\" + ts_dir + \"_\" + output_key + \".tif\"\n",
    "    clas_tif_result = save_location + \"/geotifs/magnitudes_classified_\" + ts_dir + \"_\" + output_key + \"_result.tif\"\n",
    "    color_table = \"color_table.txt\"\n",
    "    \n",
    "    ps = subprocess.Popen(('echo', color_table), stdout=subprocess.PIPE)\n",
    "    output = subprocess.check_output((func, clas_tif, clas_tif_result), stdin=ps.stdout)\n",
    "    ps.wait()\n",
    "    \n",
    "    # select only negative magnitudes\n",
    "    means_neg, breaks_indexed, breaks_indexed_neg, binary_breaks, negative_binary_breaks = select_negatives(means_orig, breaks_orig)\n",
    "    save_plot(means_neg, output_dir = save_location, save_name = \"magnitudes_negative_\" + ts_dir)\n",
    "\n",
    "    # save negative means and breaks\n",
    "    export_GTiff(tiles_data, output_dir = save_location, array = means_neg ,output_name = \"magnitudes_negative_\" + ts_dir)\n",
    "    export_GTiff(tiles_data, output_dir = save_location, array = binary_breaks ,output_name = \"breaks_binary_\" + ts_dir)\n",
    "    export_GTiff(tiles_data, output_dir = save_location, array = negative_binary_breaks ,output_name = \"breaks_binary_negative_\" + ts_dir)\n",
    "\n",
    "    dates_monitor = []\n",
    "    dates = tiles_data[0].cropped_dates\n",
    "\n",
    "    # collect dates for monitor period\n",
    "    for i in range(len(dates)):\n",
    "        if start_monitor <= dates[i]:\n",
    "            dates_monitor.append(dates[i])\n",
    "    dates_array = np.array(dates_monitor) # dates_array is the dates that are in the monitoring period\n",
    "    \n",
    "    # julian_date output\n",
    "    julian_breaks, year_breaks = get_julian_dates(dates_array,breaks_indexed)\n",
    "    negative_julian_breaks, negative_year_breaks = get_julian_dates(dates_array,breaks_indexed_neg)\n",
    "\n",
    "    # save negative means and breaks\n",
    "    export_GTiff(tiles_data, output_dir = save_location, array = julian_breaks ,output_name = \"breaks_julian_\" + ts_dir)\n",
    "    export_GTiff(tiles_data, output_dir = save_location, array = negative_julian_breaks ,output_name = \"breaks_julian_negative_\" + ts_dir)\n",
    "\n",
    "    export_GTiff(tiles_data, output_dir = save_location, array = year_breaks, output_name = \"breaks_year_\" + ts_dir)\n",
    "    export_GTiff(tiles_data, output_dir = save_location, array = negative_year_breaks, output_name = \"breaks_year_negative_\" + ts_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display webmap and store as .html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(plot_display_data_chooser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not plot_display_data_chooser.result:\n",
    "    print(\"make sure to run the block above\")\n",
    "\n",
    "m = merge_plots2(data_list = run_dict[ts_dir], base_output_dir=base_output_dir,plot_name= plot_display_data_chooser.result)\n",
    "m.save(base_output_dir + \"/\" +\"0/\" + plot_display_data_chooser.result + \".html\")\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
