{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU implementation of Bfastmonitor using Python\n",
    "The bfast package provides a highly-efficient parallel implementation for the Breaks For Additive Season and Trend (BFASTmonitor) proposed by Verbesselt et al. (2012). This notebook is based on the novel implementation, which takes advanatage of GPUs (Gieseke et al. (2020))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This code runs bfastmonitor over an entire time series folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script below runs bfastmonitor over the timeseries data downloaded in SEPAL in blocks, and patches together tiles to export mean magnitudes and breaks as geotiffs, pngs, and .npy files. The output is also displayed in a digital map. Make sure to run through the cells sequentially.\n",
    "\n",
    "* Make sure to select the G4 (recommended) or G8 when accessing the terminal. \n",
    "\n",
    "* First download data using the SEPAL time series downloader (not in this script). The downloads will be saved in your downloads folder and look like: /home/'username'/downloads/Time_series_2020-09-01_16-22-26/0|1|2|3\n",
    "\n",
    "* Import packages\n",
    "\n",
    "* Select data\n",
    "\n",
    "* Set parameters\n",
    "\n",
    "* Select monitoring period\n",
    "\n",
    "* Run bfastmonitor and save intermediate output\n",
    "\n",
    "* Load output\n",
    "\n",
    "* Merge and save output\n",
    "\n",
    "* Display output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import expanduser\n",
    "\n",
    "import wget\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import copy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "\n",
    "import json\n",
    "\n",
    "import bfast\n",
    "#from bfast import BFASTMonitor\n",
    "#from bfast.utils import crop_data_dates\n",
    "\n",
    "import csv\n",
    "from shutil import copyfile\n",
    "import pandas as pd\n",
    "from osgeo import gdal, gdal_array, osr\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout\n",
    "from ipyfilechooser import FileChooser\n",
    "import folium\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "\n",
    "# import functions from functions.py\n",
    "from functions import set_base_output_dir, set_output_dir, get_data_dict, merge_tiles, set_paths, _find_index_date, normalize, select_negatives, get_julian_dates\n",
    "from plotting_funcs import save_plot, merge_plots, classify_output, plot_output_matplotlib, export_GTiff, classify_magnitudes, merge_plots2\n",
    "\n",
    "# Import the Timeseries class from time_series.py\n",
    "from time_series import Timeseries\n",
    "print(Timeseries.__doc__)\n",
    "\n",
    "# Import widgets for GUI parameter selection\n",
    "from widgets import get_widgets, get_dates_widgets\n",
    "output_directory_chooser, k_chooser,freq_chooser,trend_chooser,hfrac_chooser,level_chooser,backend_chooser, load_chooser, block_size_chooser, plot_display_data_chooser = get_widgets()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select output directory name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(output_directory_chooser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_output_dir = set_base_output_dir(output_directory_chooser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select your timeseries folder. They are regularly stored in downloads/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = expanduser(\"~\")\n",
    "file_chooser = FileChooser(path)\n",
    "display(file_chooser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_directory = file_chooser.selected\n",
    "\n",
    "if not timeseries_directory:\n",
    "    raise Exception(\"Please choose a time series directory above with the file selector\")\n",
    "else:\n",
    "    print(timeseries_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the directories you are interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [widgets.Checkbox(value = True,description = i) for i in os.listdir(timeseries_directory)]\n",
    "widgets.VBox(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose parameters\n",
    "display(k_chooser)\n",
    "display(freq_chooser)\n",
    "display(trend_chooser)\n",
    "display(hfrac_chooser)\n",
    "display(level_chooser)\n",
    "display(backend_chooser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "k = k_chooser.result\n",
    "freq = freq_chooser.result\n",
    "trend = trend_chooser.result\n",
    "hfrac = hfrac_chooser.result\n",
    "level = round(1 - level_chooser.result,3)\n",
    "backend = backend_chooser.result\n",
    "verbose = 1\n",
    "device_id = 0\n",
    "\n",
    "parameter_string =  'k%sf%st%sh%sl%s' % (k,freq,trend,hfrac,level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose history and monitoring period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_path = os.path.join(timeseries_directory, \"0/dates.csv\")\n",
    "\n",
    "# Store dates_file\n",
    "with open(dates_path) as f:\n",
    "    dates_list = f.read().split('\\n')\n",
    "    dates = [datetime.strptime(d, '%Y-%m-%d') for d in dates_list if len(d) > 0]\n",
    "\n",
    "start_date = dates[0]\n",
    "end_date = dates[-1]\n",
    "pandas_dates = pd.date_range(start_date, end_date, freq='W')\n",
    "\n",
    "options =  [(date.strftime('%Y-%m-%d'), date) for date in pandas_dates]\n",
    "index = (0, len(options)-1)\n",
    "\n",
    "monitoring_period_chooser, history_period_chooser = get_dates_widgets(options = options, index = index)\n",
    "\n",
    "display(monitoring_period_chooser)\n",
    "display(history_period_chooser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store monitoring parameters\n",
    "start_monitor, end_monitor = monitoring_period_chooser.result\n",
    "start_hist = history_period_chooser.result\n",
    "\n",
    "print(\"start monitoring: \" , start_monitor)\n",
    "print(\"end monitoring: \" , end_monitor)\n",
    "print(\"start history: \" ,  start_hist)\n",
    "\n",
    "if history_period_chooser.result > start_monitor:\n",
    "    raise Exception(\"Your history period must start before the monitoring period\")\n",
    "\n",
    "if start_monitor < dates[50]:\n",
    "    raise Warning(\"Your history period is relatively short, did you move the monitoring date range to a later date?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to dates file and create Timeseries objects of tiles\n",
    "load_list=[]\n",
    "for xi in items:\n",
    "    if xi.value == True:\n",
    "        load_list.append(xi.description)\n",
    "\n",
    "run_dict = {}\n",
    "for directory in load_list:\n",
    "    \n",
    "    segment_location = timeseries_directory + directory + \"/\"\n",
    "    save_location = base_output_dir +\"/\"+ directory + \"/\"\n",
    "    \n",
    "    data_list = set_paths(timeseries_directory = segment_location, \n",
    "                          sh = start_hist,\n",
    "                          sm = start_monitor,\n",
    "                          em = end_monitor,\n",
    "                          parameter_string = parameter_string,\n",
    "                          save_location = save_location, \n",
    "                          \n",
    "                          check_existing = True)\n",
    "    run_dict[directory] = data_list\n",
    "\n",
    "\n",
    "# check for dirs that have already run\n",
    "del_list = []\n",
    "for directory in run_dict:\n",
    "    \n",
    "    if run_dict[directory]:\n",
    "        print(str(len(run_dict[directory])) + \" tiles found in dir \" + directory)\n",
    "    else:\n",
    "        print(\"Warning, All tiles for directory \" + directory +  \" have already generated output, if you want to run again, change your output_dir_name, change a parameter, or set check_existing above to False\")\n",
    "        del_list.append(directory)\n",
    "\n",
    "# remove dirs that have already run\n",
    "for item in del_list:\n",
    "    del run_dict[item]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose block size (512 recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(block_size_chooser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run bfast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_block = y_block = block_size_chooser.result\n",
    "\n",
    "\n",
    "for data_list in run_dict:\n",
    "    \n",
    "    # loading bar\n",
    "    with tqdm(total=len(run_dict)) as pbar1:\n",
    "        \n",
    "        # Set save location\n",
    "        save_location = base_output_dir + \"/\" + data_list\n",
    "        if not os.path.exists(save_location):\n",
    "            os.makedirs(save_location)\n",
    "        \n",
    "        # loop over tile(s) in the data_list\n",
    "        for counter, tile in enumerate(run_dict[data_list]):\n",
    "            pbar1.set_description(\"Processing tile %s out of %s\" % (counter+1, len(run_dict[data_list])) )\n",
    "\n",
    "            # Set parameters\n",
    "            tile.set_bfast_parameters(start_monitor = start_monitor, \n",
    "                                         end_monitor = end_monitor,\n",
    "                                         start_hist = start_hist,\n",
    "                                         freq = freq,\n",
    "                                         k = k,\n",
    "                                         hfrac = hfrac,\n",
    "                                         trend = trend,\n",
    "                                         level = level,\n",
    "                                         backend=backend,\n",
    "                                         verbose=verbose,\n",
    "                                         device_id=device_id)\n",
    "            \n",
    "            # Print parameters to screen\n",
    "            tile.get_bfast_parameters()\n",
    "\n",
    "            # Loop over blocks of set size\n",
    "            tile.loop_blocks(x_block_size = x_block,\n",
    "                                y_block_size = y_block)\n",
    "            \n",
    "            # Store logfile of output\n",
    "            tile.log_all_output(output_dir_name=save_location, parameter_string = parameter_string)\n",
    "            \n",
    "            # Delete data from local memory\n",
    "            run_dict[data_list][counter] = '0'\n",
    "            del(tile)\n",
    "\n",
    "            pbar1.update(1)\n",
    "\n",
    "    pbar1.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load saved output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dict = {}\n",
    "for directory in load_list:\n",
    "    \n",
    "    segment_location = timeseries_directory + directory + \"/\"\n",
    "    dates_location =  timeseries_directory + directory + \"/dates.csv\"\n",
    "    \n",
    "    data_list = set_paths(timeseries_directory = segment_location,\n",
    "                            sh = start_hist,\n",
    "                            sm = start_monitor,\n",
    "                            em = end_monitor,\n",
    "                            parameter_string = parameter_string)\n",
    "    run_dict[directory] = data_list\n",
    "    \n",
    "    for tile in data_list:\n",
    "        tile.start_monitor, tile.end_monitor = monitoring_period_chooser.result\n",
    "        tile.start_hist = history_period_chooser.result \n",
    "        tile.crop_dates(tile.dates)\n",
    "        tile.load_breaks_means_arrays_from_file(output_dir_name = base_output_dir + \"/\" +  directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output statistics and geotifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ts_dir in run_dict:\n",
    "    \n",
    "    print(\"dir\" , ts_dir)\n",
    "    save_location = base_output_dir + \"/\" + ts_dir\n",
    "    tiles_data = run_dict[ts_dir]\n",
    "    \n",
    "    # Print statistics\n",
    "    perc_lacking_data_sum, perc_breaks_sum= 0,0\n",
    "    for tile in tiles_data:\n",
    "        print(tile)\n",
    "        minus2count,minus1count,perc_lacking_data,perc_breaks = tile.check_arrays()\n",
    "        perc_breaks_sum += perc_breaks\n",
    "        perc_lacking_data_sum+= perc_lacking_data\n",
    "        \n",
    "    print(\"percentage breaks found\", perc_breaks_sum/len(tiles_data))\n",
    "    print(\"percentage cells lacking data to find results found\", perc_lacking_data_sum/len(tiles_data) , \"\\n\")\n",
    "    \n",
    "    # Merge tiles\n",
    "    if len(tiles_data) > 1:\n",
    "        means_orig, breaks_orig = merge_tiles(tiles_data,output_dir_name = save_location)\n",
    "    else:\n",
    "        means_orig = tiles_data[0].means_array\n",
    "        breaks_orig = tiles_data[0].breaks_array\n",
    "\n",
    "    # Export magnitudes and breaks\n",
    "    save_plot(means_orig, save_location, save_name = \"magnitudes_\" + ts_dir)\n",
    "    export_GTiff(tiles_data, output_dir = save_location, array = means_orig, output_name = \"magnitudes_\" + ts_dir)\n",
    "    export_GTiff(tiles_data, output_dir = save_location, array = breaks_orig, output_name = \"breaks_indexed_\" + ts_dir)\n",
    "\n",
    "    # Classify means \n",
    "    classified_means = classify_magnitudes(means_orig)\n",
    "    classified_means = np.nan_to_num(classified_means,nan=0).astype(\"uint16\")\n",
    "    export_GTiff(tiles_data, output_dir = save_location, array = classified_means, output_name = \"magnitudes_classified_\" + ts_dir)\n",
    "    \n",
    "    # add colors to classified raster\n",
    "    func = \"oft-addpct.py\"\n",
    "    output_key = save_location.replace(\"/\",\"-\").split(\"-\")[1]\n",
    "    clas_tif = save_location + \"/geotifs/magnitudes_classified_\" + ts_dir + \"_\" + output_key + \".tif\"\n",
    "    clas_tif_result = save_location + \"/geotifs/magnitudes_classified_\" + ts_dir + \"_\" + output_key + \"_result.tif\"\n",
    "    color_table = \"color_table.txt\"\n",
    "    \n",
    "    ps = subprocess.Popen(('echo', color_table), stdout=subprocess.PIPE)\n",
    "    output = subprocess.check_output((func, clas_tif, clas_tif_result), stdin=ps.stdout)\n",
    "    ps.wait()\n",
    "    \n",
    "    # select only negative magnitudes\n",
    "    means_neg, breaks_indexed, breaks_indexed_neg, binary_breaks, negative_binary_breaks = select_negatives(means_orig, breaks_orig)\n",
    "    save_plot(means_neg, output_dir = save_location, save_name = \"magnitudes_negative_\" + ts_dir)\n",
    "\n",
    "    # save negative means and breaks\n",
    "    export_GTiff(tiles_data, output_dir = save_location, array = means_neg ,output_name = \"magnitudes_negative_\" + ts_dir)\n",
    "    export_GTiff(tiles_data, output_dir = save_location, array = binary_breaks ,output_name = \"breaks_binary_\" + ts_dir)\n",
    "    export_GTiff(tiles_data, output_dir = save_location, array = negative_binary_breaks ,output_name = \"breaks_binary_negative_\" + ts_dir)\n",
    "\n",
    "    dates_monitor = []\n",
    "    dates = tiles_data[0].cropped_dates\n",
    "\n",
    "    # collect dates for monitor period\n",
    "    for i in range(len(dates)):\n",
    "        if start_monitor <= dates[i]:\n",
    "            dates_monitor.append(dates[i])\n",
    "    dates_array = np.array(dates_monitor) # dates_array is the dates that are in the monitoring period\n",
    "    \n",
    "    # julian_date output\n",
    "    julian_breaks, year_breaks = get_julian_dates(dates_array,breaks_indexed)\n",
    "    negative_julian_breaks, negative_year_breaks = get_julian_dates(dates_array,breaks_indexed_neg)\n",
    "\n",
    "    # save negative means and breaks\n",
    "    export_GTiff(tiles_data, output_dir = save_location, array = julian_breaks ,output_name = \"breaks_julian_\" + ts_dir)\n",
    "    export_GTiff(tiles_data, output_dir = save_location, array = negative_julian_breaks ,output_name = \"breaks_julian_negative_\" + ts_dir)\n",
    "\n",
    "    export_GTiff(tiles_data, output_dir = save_location, array = year_breaks, output_name = \"breaks_year_\" + ts_dir)\n",
    "    export_GTiff(tiles_data, output_dir = save_location, array = negative_year_breaks, output_name = \"breaks_year_negative_\" + ts_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display webmap and store as .html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(plot_display_data_chooser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not plot_display_data_chooser.result:\n",
    "    print(\"make sure to run the block above\")\n",
    "\n",
    "m = merge_plots2(data_list = run_dict[ts_dir], base_output_dir=base_output_dir,plot_name= plot_display_data_chooser.result)\n",
    "m.save(base_output_dir + \"/\" +\"0/\" + plot_display_data_chooser.result + \".html\")\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
